[run]
# the base directory for the analysis **output**
basedir = root

######### Condor DAG specific inputs ########
[pe_dag]
# the location of the directory to contain the Condor DAG submission files
# (defaults to "basedir/submit")
;submit = 

# the prefix of the name for the Condor DAGMan submit file (defaults to
# "dag_cwinpy_pe"). "dag" will always be prepended.
;name =

# a flag specifying whether to automatically submit the DAG after its creation
# (defaults to False)
submitdag = False

# a flag saying whether to build the DAG (defaults to True)
;build =

# set whether running on the OSG (defaults to False). If using the OSG it
# expects you to be within an IGWN conda environment or using the singularity
# container option below.
;osg =

# if wanting to run on the OSG with the latest development version of cwinpy,
# which is within a Singularity container, set this flag to True
;singularity

# if running on the OSG you can select desired sites to run on
# see https://computing.docs.ligo.org/guide/condor/submission/#DESIRED_Sites
;desired_sites =
;undesired_sites =

######## cwinpy_pe Job options ########
[pe_job]
# the location of the cwinpy_pe executable to use (defaults to try and find
# cwinpy_pe in the current user PATH)
;executable =

# set the Condor universe (defaults to "vanilla") 
;universe =

# directory location for the output from stdout from the Job (defaults to
# "basedir/log")
;out =

# directory location for the output from stderr from the Job (defaults to
# "basedir/log")
;error =

# directory location for any logging information from the jobs (defaults to
# "basedir/log")
;log =

# the location of the directory to contain the Condor job submission files
# (defaults to "basedir/submit")
;submit =

# the amount of available memory request for each job (defaults to 4 Gb)
# [Note: this is required for vanilla jobs on LIGO Scientific Collaboration
# computer clusters]
;request_memory =

# the amount of disk space required for each job (defaults to 1 Gb)
# [Note: this is required for vanilla jobs on LIGO Scientific Collaboration
# computer clusters]
;request_disk =

# the number of CPUs the job requires (defaults to 1, cwinpy_pe is not
# currently parallelised in any way)
;request_cpus =

# additional Condor job requirements (defaults to None)
;requirements =

# set how many times the DAG will retry a job on failure (default to 2)
;retry =

# Job accounting group and user [Note: these are required on LIGO Scientific
# Collaboration computer cluster, but may otherwise be left out, see
; https://accounting.ligo.org/user for valid accounting tags]
;accounting_group =
accounting_group_user = albert.einstein

####### Source and solar system ephemeride files ##########
[ephemerides]
# The pulsar parameter files, where all files are expected to have the
# extension ".par". This can either be:
#  - the path to a single file (if running with a single source)
#  - a list of parameter files
#  - a directory (or glob-able directory pattern) containing parameter files
#  - a combination of a list of directories and/or files
pulsars = /root/pulsars

# Pulsar "injection" parameter files containing simulated signal parameters to
# add to the data. If not given then no injections will be performed. If given
# it should be in the same style as the "pulsars" section.
;injections =

# Locations of the Earth and Sun ephemerides. If not given then the ephemerides
# will be automatically determined from the pulsar parameter information. The
# values should be dictionaries keyed to the ephemeris type, e.g., "DE405", and
# pointing to the location of the ephemeris file.
;earth =
;sun =

######## PE specific options ########
[pe]

# The number of parallel runs for each pulsar. These will be combined to
# create the final output. This defaults to 1.
;n_parallel =

# The period for automatically restarting HTCondor PE jobs to prevent a hard
# eviction. If not given this defaults to 43200 seconds
;periodic-restart-time =

# The directory within basedir into which to output the results in individual
# directories named using the PSRJ name (defaults to "results")
;results =

# Locations of heterodyned data files produced at twice the rotation frequency
# of the source. This must be a dictionary keyed to detector names. The value
# of each detector-keyed item can be:
#  - the path to a single file (if analysing one detector)
#  - a directory (or glob-able directory pattern) containing (only) data files
#  - a list of files (or directories/directory patterns)
#  - a dictionary keyed to pulsar PSRJ names containing the full paths to the
#    associated data file
# The file name or path for each dataset must contain the associated pulsar
# PSRJ name.
# This can alternatively be just given as "data-file"
data-file-2f = {"H1": "/root/detector1/2f/*/*", "L1": "/root/detector2/2f/*/*"}

# Locations of heterodyned data files produced at the rotation frequency of the
# source (if required). This must be a dictionary keyed to detector names. The value of each
# detector-keyed item can be:
#  - the path to a single file (if analysing one detector)
#  - a directory (or glob-able directory pattern) containing (only) data files
#  - a list of files (or directories/directory patterns)
#  - a dictionary keyed to pulsar PSRJ names containing the full paths to the
#    associated data file
# The file name or path for each dataset must contain the associated pulsar
# PSRJ name. [Note: this is not required if only analysing data at twice the
# rotation frequency]
data-file-1f = {"H1": "/root/detector1/1f/*/*", "L1": "/root/detector2/1f/*/*"}

# GPS start and end times to crop the input data to if required. These can only
# be single values, so all files will be cropped to the same time range. If not
# given then the full data range will be used.
;crop-start =
;crop-end =

# Set a dictionary of keyword arguments to be used by the HeterodynedData class
# that the data files will be read into.
;data_kwargs = {}

# Set this boolean flag to state whether to run parameter estimation with a
# likelihood that uses the coherent combination of data from all detectors
# specified. This defaults to True.
;coherent =

# Set this boolean flag to state whether to run the parameter estimation for
# each detector independently. This defaults to False.
;incoherent =

# Flags to set to generate simulated Gaussian noise to analyse, if data files
# are not given. "fake-asd-1f" is used to produce simulated noise at the source
# rotation frequency and "fake-asd-2f" (or just "fake-asd" is used to produce
# simulated noise at twice the source rotation frequency). The values these can
# take are:
#  - a list of detectors, in which case the detector's design sensitivity curve
#    will be used when generating the noise for each pulsar
#  - a dictionary, keyed to detector names, either giving a value that is an
#    amplitude spectral density value to be used, or a file containing a
#    frequency series of amplitude spectral densities to use
;fake-asd-1f =
;fake-asd-2f =

# Flags to set the start time, end time time step and random seed for the fake
# data generation. Either both 'fake-start' and 'fake-end' must be set, or
# neither should be set. Each of the time values can either be:
#  - a single integer or float giving the GPS time/time step
#  - a dictionary keyed to the detector names containing the value for the
#    given detector
# If not given the fake data for any required detectors will start at a GPS
# time of 1000000000 and end at 1000086400 (i.e., for one day), with a time
# step of 60 seconds
;fake-start =
;fake-end =
;fake-dt =
;fake-seed =

# The prior distributions to use for each pulsar. The value of this can either
# be:
#  - a single prior file (in bilby format) to use for all pulsars
#  - a list of prior files, where each filename contains the PSRJ name of the
#    associated pulsar
#  - a directory, or glob-able directory pattern, containing the prior files,
#    where each filename contains the PSRJ name of the associated pulsar
#  - a dictionary with prior file names keyed to the associated pulsar
# If not given then default priors will be used. If using data at just twice
# the rotation frequency the default priors are:
#   h0 = Uniform(minimum=0.0, maximum=1.0e-22, name='h0')
#   phi0 = Uniform(minimum=0.0, maximum=pi, name='phi0')
#   iota = Sine(minimum=0.0, maximum=pi, name='iota')
#   psi = Uniform(minimum=0.0, maximum=pi/2, name='psi')
# For data at just the rotation frequency the default priors are:
#   c21 = Uniform(minimum=0.0, maximum=1.0e-22, name='c21')
#   phi21 = Uniform(minimum=0.0, maximum=2*pi, name='phi21')
#   iota = Sine(minimum=0.0, maximum=pi, name='iota')
#   psi = Uniform(minimum=0.0, maximum=pi/2, name='psi')
# And, for data at both frequencies, the default priors are:
#   c21 = Uniform(minimum=0.0, maximum=1.0e-22, name='c21')
#   c22 = Uniform(minimum=0.0, maximum=1.0e-22, name='c22')
#   phi21 = Uniform(minimum=0.0, maximum=2*pi, name='phi21')
#   phi22 = Uniform(minimum=0.0, maximum=2*pi, name='phi22')
#   iota = Sine(minimum=0.0, maximum=pi, name='iota')
#   psi = Uniform(minimum=0.0, maximum=pi/2, name='psi')
priors = /root/priors

# Flag to say whether to output the injected/recovered signal-to-noise ratios
# (defaults to False)
;output_snr =

# The location within basedir for the cwinpy_pe configuration files
# generated to each source (defaults to "configs")
;config =

# The stochastic sampling package to use (defaults to "dynesty")
;sampler =

# A dictionary of any keyword arguments required by the sampler package
# (defaults to None)
;sampler_kwargs =

# A flag to set whether to use the numba-enable likelihood function (defaults
# to True)
;numba =

# A flag to set whether to generate and use a reduced order quadrature for the
# likelihood calculation (defaults to False)
;roq =

# A dictionary of any keyword arguments required by the ROQ generation
;roq_kwargs =